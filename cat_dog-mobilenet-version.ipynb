{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cat and Dog classification.\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "image_gen=ImageDataGenerator(rotation_range=30,width_shift_range=0.1,\n",
    "            height_shift_range=0.1,rescale=1/255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,\n",
    "            fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model.\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import ZeroPadding2D,Conv2D,BatchNormalization,DepthwiseConv2D,Input,Activation,GlobalAveragePooling2D,Reshape,Dropout\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.activations import relu\n",
    "relu_advanced = lambda x: relu(x, max_value=6.)\n",
    "\n",
    "def normal_conv_block(inputs,filters,alpha,kernel=(3,3),strides=(1,1)):\n",
    "    filters=int(filters*alpha)\n",
    "    x=ZeroPadding2D(padding=((0,1),(0,1)),name='conv1_pad')(inputs)\n",
    "    x=Conv2D(filters,kernel,padding='valid',use_bias=False,strides=strides,name='conv1')(x)\n",
    "    x=BatchNormalization(axis=1 if K.image_data_format() == 'channels_first' else -1,name='conv1_bn')(x)\n",
    "    return Activation(relu_advanced)(x)\n",
    "def depth_wise_conv_block(inputs, pointwise_conv_filters, alpha,depth_multiplier=1, strides=(1, 1), block_id=1):\n",
    "    pointwise_conv_filters = int(pointwise_conv_filters * alpha)\n",
    "\n",
    "    if strides == (1, 1):\n",
    "        x = inputs\n",
    "    else:\n",
    "        x =ZeroPadding2D(((0, 1), (0, 1)),name='conv_pad_%d' % block_id)(inputs)\n",
    "    x = DepthwiseConv2D((3, 3),\n",
    "                               padding='same' if strides == (1, 1) else 'valid',\n",
    "                               depth_multiplier=depth_multiplier,\n",
    "                               strides=strides,\n",
    "                               use_bias=False,\n",
    "                               name='conv_dw_%d' % block_id)(x)\n",
    "    x = BatchNormalization(axis=1 if K.image_data_format() == 'channels_first' else -1, name='conv_dw_%d_bn' % block_id)(x)\n",
    "        \n",
    "    x = Activation(relu_advanced)(x)\n",
    "\n",
    "    x = Conv2D(pointwise_conv_filters, (1, 1),\n",
    "                      padding='same',\n",
    "                      use_bias=False,\n",
    "                      strides=(1, 1),\n",
    "                      name='conv_pw_%d' % block_id)(x)\n",
    "    x = BatchNormalization(axis=1 if K.image_data_format() == 'channels_first' else -1,\n",
    "                                  name='conv_pw_%d_bn' % block_id)(x)\n",
    "    return Activation(relu_advanced)(x)\n",
    "    \n",
    "    \n",
    "#Main model\n",
    "def get_model(input_shape=(150,150,3),\n",
    "              alpha=1.0,\n",
    "              depth_multiplier=1,\n",
    "              dropout=1e-3,\n",
    "              include_top=True,\n",
    "              input_tensor=None,\n",
    "              pooling=None,\n",
    "              classes=2,\n",
    "              ):\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    \n",
    "    \n",
    "    x = normal_conv_block(img_input, 32, alpha, strides=(2, 2))\n",
    "    x = depth_wise_conv_block(x, 64, alpha, depth_multiplier, block_id=1)\n",
    "\n",
    "    x = depth_wise_conv_block(x, 128, alpha, depth_multiplier,strides=(2, 2), block_id=2)\n",
    "    x = depth_wise_conv_block(x, 128, alpha, depth_multiplier, block_id=3)\n",
    "\n",
    "    x = depth_wise_conv_block(x, 256, alpha, depth_multiplier,strides=(2, 2), block_id=4)\n",
    "    x = depth_wise_conv_block(x, 256, alpha, depth_multiplier, block_id=5)\n",
    "\n",
    "    x = depth_wise_conv_block(x, 512, alpha, depth_multiplier, strides=(2, 2), block_id=6)\n",
    "    x = depth_wise_conv_block(x, 512, alpha, depth_multiplier, block_id=7)\n",
    "    x = depth_wise_conv_block(x, 512, alpha, depth_multiplier, block_id=8)\n",
    "    x = depth_wise_conv_block(x, 512, alpha, depth_multiplier, block_id=9)\n",
    "    x = depth_wise_conv_block(x, 512, alpha, depth_multiplier, block_id=10)\n",
    "    x = depth_wise_conv_block(x, 512, alpha, depth_multiplier, block_id=11)\n",
    "\n",
    "    x = depth_wise_conv_block(x, 1024, alpha, depth_multiplier,strides=(2, 2), block_id=12)\n",
    "    x = depth_wise_conv_block(x, 1024, alpha, depth_multiplier, block_id=13)\n",
    "    \n",
    "    if include_top:\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            shape = (int(1024 * alpha), 1, 1)\n",
    "        else:\n",
    "            shape = (1, 1, int(1024 * alpha))\n",
    "\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Reshape(shape, name='reshape_1')(x)\n",
    "        x = Dropout(dropout, name='dropout')(x)\n",
    "        x = Conv2D(classes, (1, 1),\n",
    "                          padding='same',\n",
    "                          name='conv_preds')(x)\n",
    "        x = Reshape((classes,), name='reshape_2')(x)\n",
    "        x = Activation('softmax', name='act_softmax')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "            \n",
    "    return Model(img_input,x)\n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_33 (InputLayer)        (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 151, 151, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 75, 75, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 75, 75, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_232 (Activation)  (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 75, 75, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 75, 75, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_233 (Activation)  (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 75, 75, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 75, 75, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_234 (Activation)  (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 76, 76, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 37, 37, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 37, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_235 (Activation)  (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 37, 37, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 37, 37, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_236 (Activation)  (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 37, 37, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 37, 37, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_237 (Activation)  (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 37, 37, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 37, 37, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_238 (Activation)  (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 18, 18, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 18, 18, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_239 (Activation)  (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 18, 18, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 18, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_240 (Activation)  (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 18, 18, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 18, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_241 (Activation)  (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 18, 18, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 18, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_242 (Activation)  (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 19, 19, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 9, 9, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 9, 9, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_243 (Activation)  (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 9, 9, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 9, 9, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_244 (Activation)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 9, 9, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 9, 9, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_245 (Activation)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 9, 9, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 9, 9, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_246 (Activation)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 9, 9, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 9, 9, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_247 (Activation)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 9, 9, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 9, 9, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_248 (Activation)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 9, 9, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 9, 9, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_249 (Activation)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 9, 9, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 9, 9, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_250 (Activation)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 9, 9, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 9, 9, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_251 (Activation)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 9, 9, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 9, 9, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_252 (Activation)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 9, 9, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 9, 9, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_253 (Activation)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 9, 9, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 9, 9, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_254 (Activation)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_255 (Activation)  (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 4, 4, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_256 (Activation)  (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_257 (Activation)  (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 4, 4, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_258 (Activation)  (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 2)           2050      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 3,230,914\n",
      "Trainable params: 3,209,026\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=get_model()\n",
    "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18743 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=16\n",
    "\n",
    "train_img_gen=image_gen.flow_from_directory('E:/CATS_DOGS/CATS_DOGS/train',target_size=(150,150),batch_size=batch_size,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6251 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_img_gen=image_gen.flow_from_directory('E:/CATS_DOGS/CATS_DOGS/test',target_size=(150,150),batch_size=batch_size,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 101s 671ms/step - loss: 0.8340 - acc: 0.5292 - val_loss: 1.3715 - val_acc: 0.5417\n",
      "Epoch 2/100\n",
      " 90/150 [=================>............] - ETA: 22s - loss: 0.7098 - acc: 0.5736"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 80000 bytes but only got 0. Skipping tag 64640\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 307363840 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 307888128 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 328728576 bytes but only got 0. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1385474 bytes but only got 5357. Skipping tag 513\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3846701056 bytes but only got 0. Skipping tag 2\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 5357. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 60s 401ms/step - loss: 0.6998 - acc: 0.5829 - val_loss: 1.0886 - val_acc: 0.4688\n",
      "Epoch 3/100\n",
      " 85/150 [================>.............] - ETA: 25s - loss: 0.7005 - acc: 0.5868"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 262146 bytes but only got 0. Skipping tag 2\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 262151 bytes but only got 0. Skipping tag 56\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 62s 415ms/step - loss: 0.6891 - acc: 0.5871 - val_loss: 0.7900 - val_acc: 0.5312\n",
      "Epoch 4/100\n",
      "141/150 [===========================>..] - ETA: 3s - loss: 0.6760 - acc: 0.6006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 18350080 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 6. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 64s 426ms/step - loss: 0.6732 - acc: 0.6063 - val_loss: 0.6897 - val_acc: 0.5312\n",
      "Epoch 5/100\n",
      "126/150 [========================>.....] - ETA: 9s - loss: 0.6483 - acc: 0.6463"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 61s 409ms/step - loss: 0.6444 - acc: 0.6433 - val_loss: 0.7994 - val_acc: 0.6406\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 58s 385ms/step - loss: 0.6405 - acc: 0.6396 - val_loss: 1.1545 - val_acc: 0.5729\n",
      "Epoch 7/100\n",
      " 62/150 [===========>..................] - ETA: 32s - loss: 0.6182 - acc: 0.6683"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6553600 bytes but only got 0. Skipping tag 49\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1050744 bytes but only got 4951. Skipping tag 51\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 293339136 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 293863424 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 295698432 bytes but only got 0. Skipping tag 10\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 296222720 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 14745600 bytes but only got 0. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 25624576 bytes but only got 0. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 317718528 bytes but only got 4956. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 4952. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 287178752 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 287703040 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 286654464 bytes but only got 4956. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/150 [===========================>..] - ETA: 2s - loss: 0.6190 - acc: 0.6617"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 404094976 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 404619264 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 425459712 bytes but only got 0. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1385474 bytes but only got 6833. Skipping tag 513\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 6833. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 57s 381ms/step - loss: 0.6222 - acc: 0.6592 - val_loss: 0.7341 - val_acc: 0.5833\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 57s 381ms/step - loss: 0.6079 - acc: 0.6783 - val_loss: 0.6836 - val_acc: 0.6406\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.5975 - acc: 0.6800 - val_loss: 0.6307 - val_acc: 0.6927\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.5816 - acc: 0.6942 - val_loss: 0.6716 - val_acc: 0.6667\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.5779 - acc: 0.6963 - val_loss: 0.6696 - val_acc: 0.6406\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 58s 385ms/step - loss: 0.5602 - acc: 0.7096 - val_loss: 0.9395 - val_acc: 0.5573\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 59s 395ms/step - loss: 0.5456 - acc: 0.7250 - val_loss: 1.0747 - val_acc: 0.6354\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 58s 386ms/step - loss: 0.5465 - acc: 0.7186 - val_loss: 0.6293 - val_acc: 0.6458\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 57s 382ms/step - loss: 0.5461 - acc: 0.7254 - val_loss: 0.8363 - val_acc: 0.5938\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.5228 - acc: 0.7383 - val_loss: 0.9343 - val_acc: 0.6510\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.5121 - acc: 0.7542 - val_loss: 0.4659 - val_acc: 0.7812\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 58s 385ms/step - loss: 0.5074 - acc: 0.7442 - val_loss: 0.5351 - val_acc: 0.7604\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 58s 384ms/step - loss: 0.5062 - acc: 0.7488 - val_loss: 0.5781 - val_acc: 0.7448\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 57s 382ms/step - loss: 0.4948 - acc: 0.7675 - val_loss: 0.6358 - val_acc: 0.7396\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 57s 382ms/step - loss: 0.4668 - acc: 0.7717 - val_loss: 0.5797 - val_acc: 0.7656\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 57s 383ms/step - loss: 0.4810 - acc: 0.7788 - val_loss: 0.5196 - val_acc: 0.7500\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.4505 - acc: 0.7950 - val_loss: 0.5528 - val_acc: 0.8125\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.4659 - acc: 0.7758 - val_loss: 0.4868 - val_acc: 0.7500\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.4453 - acc: 0.7850 - val_loss: 0.4507 - val_acc: 0.7865\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.4422 - acc: 0.7954 - val_loss: 0.5468 - val_acc: 0.7656\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.4385 - acc: 0.7913 - val_loss: 0.5560 - val_acc: 0.6979\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.4241 - acc: 0.8032 - val_loss: 0.8930 - val_acc: 0.7031\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 58s 384ms/step - loss: 0.4373 - acc: 0.7963 - val_loss: 0.4029 - val_acc: 0.8281\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.4165 - acc: 0.8054 - val_loss: 0.5246 - val_acc: 0.7656\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.3931 - acc: 0.8242 - val_loss: 0.9536 - val_acc: 0.6615\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.3938 - acc: 0.8213 - val_loss: 0.3952 - val_acc: 0.8229\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.3750 - acc: 0.8342 - val_loss: 0.3676 - val_acc: 0.8385\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.4075 - acc: 0.8221 - val_loss: 0.8241 - val_acc: 0.7031\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.3803 - acc: 0.8321 - val_loss: 0.3632 - val_acc: 0.8177\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.3694 - acc: 0.8317 - val_loss: 0.4004 - val_acc: 0.8125\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.3876 - acc: 0.8283 - val_loss: 0.6549 - val_acc: 0.8177\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.3832 - acc: 0.8187 - val_loss: 0.6839 - val_acc: 0.6562\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 57s 377ms/step - loss: 0.3464 - acc: 0.8521 - val_loss: 0.4835 - val_acc: 0.8281\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 57s 382ms/step - loss: 0.3483 - acc: 0.8479 - val_loss: 0.4525 - val_acc: 0.8125\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.3472 - acc: 0.8425 - val_loss: 0.3992 - val_acc: 0.8385\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.3508 - acc: 0.8490 - val_loss: 0.3752 - val_acc: 0.8281\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.3324 - acc: 0.8558 - val_loss: 0.3084 - val_acc: 0.9010\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.3271 - acc: 0.8575 - val_loss: 0.3674 - val_acc: 0.8281\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.3047 - acc: 0.8675 - val_loss: 0.5742 - val_acc: 0.7240\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 57s 383ms/step - loss: 0.3187 - acc: 0.8587 - val_loss: 0.3680 - val_acc: 0.8177\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 57s 383ms/step - loss: 0.3324 - acc: 0.8562 - val_loss: 0.4038 - val_acc: 0.8490\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.3196 - acc: 0.8550 - val_loss: 0.5822 - val_acc: 0.7604\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.3298 - acc: 0.8531 - val_loss: 0.2910 - val_acc: 0.8958\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.3061 - acc: 0.8712 - val_loss: 0.2953 - val_acc: 0.8646\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 57s 377ms/step - loss: 0.3012 - acc: 0.8804 - val_loss: 0.2414 - val_acc: 0.9010\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.3029 - acc: 0.8733 - val_loss: 0.2403 - val_acc: 0.8906\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.2985 - acc: 0.8725 - val_loss: 0.5812 - val_acc: 0.7865\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.2955 - acc: 0.8721 - val_loss: 0.3509 - val_acc: 0.8594\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 57s 377ms/step - loss: 0.2975 - acc: 0.8775 - val_loss: 0.7118 - val_acc: 0.7604\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.3011 - acc: 0.8667 - val_loss: 0.2786 - val_acc: 0.8906\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.2867 - acc: 0.8842 - val_loss: 0.3331 - val_acc: 0.8490\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.2650 - acc: 0.8883 - val_loss: 0.2346 - val_acc: 0.9323\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 57s 377ms/step - loss: 0.2803 - acc: 0.8862 - val_loss: 0.2559 - val_acc: 0.9010\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 57s 377ms/step - loss: 0.2614 - acc: 0.8917 - val_loss: 0.2369 - val_acc: 0.9010\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.2826 - acc: 0.8827 - val_loss: 0.3390 - val_acc: 0.8542\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.2850 - acc: 0.8788 - val_loss: 0.3037 - val_acc: 0.8750\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 58s 384ms/step - loss: 0.2776 - acc: 0.8925 - val_loss: 0.2396 - val_acc: 0.8906\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 57s 382ms/step - loss: 0.2583 - acc: 0.8921 - val_loss: 0.2644 - val_acc: 0.8854\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 57s 383ms/step - loss: 0.2549 - acc: 0.8857 - val_loss: 0.3866 - val_acc: 0.8542\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 61s 410ms/step - loss: 0.2647 - acc: 0.8842 - val_loss: 0.3985 - val_acc: 0.8281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "150/150 [==============================] - 57s 382ms/step - loss: 0.2600 - acc: 0.8938 - val_loss: 0.3883 - val_acc: 0.8125\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 57s 381ms/step - loss: 0.2648 - acc: 0.8879 - val_loss: 0.3265 - val_acc: 0.8646\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.2708 - acc: 0.8829 - val_loss: 0.3016 - val_acc: 0.8958\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 57s 381ms/step - loss: 0.2464 - acc: 0.8942 - val_loss: 0.2489 - val_acc: 0.8854\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.2502 - acc: 0.9025 - val_loss: 0.3670 - val_acc: 0.8646\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.2475 - acc: 0.8958 - val_loss: 1.2104 - val_acc: 0.6562\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.2517 - acc: 0.8892 - val_loss: 0.1921 - val_acc: 0.9323\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.2400 - acc: 0.8971 - val_loss: 0.4421 - val_acc: 0.8333\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.2445 - acc: 0.8929 - val_loss: 0.3943 - val_acc: 0.8698\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.2331 - acc: 0.9037 - val_loss: 0.3026 - val_acc: 0.8542\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.2386 - acc: 0.8988 - val_loss: 0.2717 - val_acc: 0.9062\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.2459 - acc: 0.9054 - val_loss: 0.1919 - val_acc: 0.9167\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.2280 - acc: 0.9050 - val_loss: 0.7921 - val_acc: 0.7656\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.2241 - acc: 0.9067 - val_loss: 0.2980 - val_acc: 0.8958\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.2371 - acc: 0.8913 - val_loss: 0.1985 - val_acc: 0.9219\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.2369 - acc: 0.9079 - val_loss: 0.2692 - val_acc: 0.8958\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 57s 382ms/step - loss: 0.2396 - acc: 0.9050 - val_loss: 0.3766 - val_acc: 0.8281\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.2404 - acc: 0.9000 - val_loss: 0.2161 - val_acc: 0.9010\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.2491 - acc: 0.8983 - val_loss: 0.3134 - val_acc: 0.8698\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.2216 - acc: 0.9179 - val_loss: 0.2717 - val_acc: 0.8958\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.2165 - acc: 0.9058 - val_loss: 0.2238 - val_acc: 0.9062\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.2192 - acc: 0.9129 - val_loss: 0.2810 - val_acc: 0.8906\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.2038 - acc: 0.9225 - val_loss: 0.2864 - val_acc: 0.8698\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 57s 377ms/step - loss: 0.2142 - acc: 0.9139 - val_loss: 0.4599 - val_acc: 0.7604\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.2315 - acc: 0.9062 - val_loss: 0.1823 - val_acc: 0.9375\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.2157 - acc: 0.9133 - val_loss: 0.2675 - val_acc: 0.9010\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.2230 - acc: 0.9054 - val_loss: 0.1989 - val_acc: 0.9062\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.2039 - acc: 0.9146 - val_loss: 0.1857 - val_acc: 0.9271\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.2200 - acc: 0.9125 - val_loss: 0.3127 - val_acc: 0.8646\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 57s 377ms/step - loss: 0.1973 - acc: 0.9238 - val_loss: 0.2303 - val_acc: 0.8906\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.2070 - acc: 0.9217 - val_loss: 0.3762 - val_acc: 0.8542\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.2377 - acc: 0.9054 - val_loss: 0.1791 - val_acc: 0.9323\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 57s 377ms/step - loss: 0.2008 - acc: 0.9165 - val_loss: 0.2244 - val_acc: 0.8958\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.2171 - acc: 0.9117 - val_loss: 0.2935 - val_acc: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bca98d3f60>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_img_gen,epochs=100,steps_per_epoch=150,validation_data=test_img_gen,validation_steps=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('Dog_cat_mobilenet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
